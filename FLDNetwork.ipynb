{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "MdmYfVM_sOwd",
    "outputId": "0bc5ca0c-8001-4c92-cbb3-44bf9112107e"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir,makedirs\n",
    "from os.path import isfile,join\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "import cv2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Hyper-Parameters\n",
    "'''\n",
    "image_H = 96\n",
    "image_W = 96\n",
    "grayscale = True\n",
    "batch_size = 16\n",
    "learning_rate=0.001\n",
    "momentum = 0\n",
    "decay = 0\n",
    "epochs = 100\n",
    "droupout= 0.1\n",
    "gradient_clipping = 0.1\n",
    "nFilters = 128\n",
    "nlandmarks = nLabels = 68\n",
    "K=45\n",
    "img_rows = 96\n",
    "img_cols = 96\n",
    "img_channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "yv-gK_mPmEX2"
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "T4eoPQGnmFaS",
    "outputId": "832b6559-c550-4e1a-cea0-46e440c6307d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-b5e1f8a6-1246-4d44-b37b-f1235af78aa7\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-b5e1f8a6-1246-4d44-b37b-f1235af78aa7\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving ibug.zip to ibug.zip\n",
      "User uploaded file \"ibug.zip\" with length 32805658 bytes\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "      name=fn, length=len(uploaded[fn])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "cTBAQZQ9mIvC",
    "outputId": "cb077e79-3ee5-4a7b-b97a-ee83bf92f0e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datalab       folderibug11  folderibug2  folderibug6  ibug.zip\r\n",
      "folderibug    folderibug12  folderibug3  folderibug7  image_003_1.jpg\r\n",
      "folderibug1   folderibug13  folderibug4  folderibug8\r\n",
      "folderibug10  folderibug14  folderibug5  folderibug9\r\n"
     ]
    }
   ],
   "source": [
    "#files.os.listdir()\n",
    "!ls\n",
    "#!rm ibug\" \"\"(\"3\")\".zip\n",
    "#!rm ibug.zip\n",
    "#!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "WFGepx0kmNFs",
    "outputId": "49a9eb85-9af2-4e09-c163-1142f072070c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<zipfile.ZipFile filename='ibug.zip' mode='r'>\n",
      "<zipfile.ZipFile filename='ibug.zip' mode='r'>\n",
      "datalab       folderibug11  folderibug2  folderibug6  ibug.zip\n",
      "folderibug    folderibug12  folderibug3  folderibug7  image_003_1.jpg\n",
      "folderibug1   folderibug13  folderibug4  folderibug8\n",
      "folderibug10  folderibug14  folderibug5  folderibug9\n"
     ]
    }
   ],
   "source": [
    "#to extract ziped folder to unzipped folder named folderibug\n",
    "\n",
    "import zipfile\n",
    "path =\"ibug.zip\"\n",
    "directory =\"folderibug\"\n",
    "zip_ref = zipfile.ZipFile(path, 'r')\n",
    "print(zip_ref)\n",
    "zip_ref.extractall(directory)\n",
    "print(zip_ref)\n",
    "zip_ref.close()\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bLMkCMXwMQ04",
    "outputId": "8e0a334b-c5c7-4813-b513-10fd36d8bc1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exist, images will be written in asme folder\n"
     ]
    }
   ],
   "source": [
    "# To convert images in folderibug to grayscale images - folder name - GrayFolder\n",
    "\n",
    "path = directory\n",
    "dstpath = \"GrayFolder\"\n",
    "try:\n",
    "    makedirs(dstpath)\n",
    "except:\n",
    "    print (\"Directory already exist, images will be written in asme folder\")\n",
    "\n",
    "# Folder won't used\n",
    "files = [f for f in listdir(path) if isfile(join(path,f))] \n",
    "\n",
    "for image in files:\n",
    " \n",
    "    try:\n",
    "        if image.endswith('.jpg'):\n",
    "          img = cv2.imread(os.path.join(path,image))\n",
    "          gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "          dstPath = join(dstpath,image)\n",
    "          cv2.imwrite(dstPath,gray)\n",
    "         \n",
    "    except:\n",
    "        print (\"{} is not converted\".format(image))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "hrezk8OnmZao",
    "outputId": "95417a29-6ff0-46db-84c8-f0a37f777604"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#To load images using cv2, the output wil be list of images which are then converted to numpy array\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    \n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "        \n",
    "    return images\n",
    "\n",
    "\n",
    "# your images in a list\n",
    "imgs = load_images_from_folder(dstpath)\n",
    "#print(imgs)\n",
    "#print(type(imgs))\n",
    "#images to array\n",
    "images = np.asarray(imgs)\n",
    "print(len(images))\n",
    "\n",
    "print(type(images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "colab_type": "code",
    "id": "BDwCtyHTmeq5",
    "outputId": "e6a72500-8617-4ff4-dc9f-404d5e7d2b58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFMCAYAAABCsp4mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8621f25b70>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135\n",
      "(135, 96, 96, 3)\n"
     ]
    }
   ],
   "source": [
    "# Pre-processing - resize of images to 96x96\n",
    "image_Grayscale = []\n",
    "images_resized = []\n",
    "for img in images:\n",
    "  #print(type(images))\n",
    "  resized = cv2.resize(img,(96,96))\n",
    "  #print(type(resized))\n",
    "  images_resized.append(resized)\n",
    "\n",
    "print(type(images_resized))\n",
    "plt.imshow(images_resized[134],cmap= \"gray\"), plt.axis(\"off\")\n",
    "plt.show()\n",
    "print(len(images_resized))\n",
    "#print(images_resized.shape)\n",
    "Fimages = np.asarray(images_resized)\n",
    "print(Fimages.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "4AEkWrWKzUbT"
   },
   "outputs": [],
   "source": [
    "train_x = []\n",
    "train_y = []\n",
    "test_x = []\n",
    "test_y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "NW2i_WENzW7q",
    "outputId": "c6e8bfb9-93eb-4bbd-c9b6-c3aaed444f22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "135\n",
      "(135,)\n",
      "<class 'list'>\n",
      "135\n",
      "<built-in method count of list object at 0x7f8621f2ce08>\n",
      "<class 'list'>\n",
      "107\n",
      "<class 'list'>\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "print(type(images))\n",
    "print(len(images))\n",
    "print(images.shape)\n",
    "print(type(images_resized))\n",
    "print(len(images_resized))\n",
    "print(images_resized.count)\n",
    "\n",
    "# Splitting training and testing data (80:20 used index value to split)\n",
    "\n",
    "train_x = []\n",
    "train_y = []\n",
    "\n",
    "from itertools import chain\n",
    "train_x = list(chain(images_resized[0:107]))\n",
    "print(type(train_x))\n",
    "print(len(train_x))\n",
    "train_y = list(chain(images_resized[108:len(images_resized)]))\n",
    "print(type(train_y))\n",
    "print(len(train_y))\n",
    "\n",
    "train_x = np.asarray(train_x)\n",
    "train_y = np.asarray(train_y)\n",
    "\n",
    "train_x = train_x.astype('float32')\n",
    "train_x = train_x / 255.0\n",
    "\n",
    "train_y = train_y.astype('float32')\n",
    "train_y = train_y / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(r'C:\\Users\\Meers\\Documents\\Techie\\InkersIntern\\Phase2\\Merget\\Merget\\network\\config\\kernel45.txt')\n",
    "kernel45 = np.fromfile(f, dtype = np.float32, count = -1, sep = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "colab_type": "code",
    "id": "-Ps6ujB8_ycf",
    "outputId": "61ede475-1a2d-4a13-ffd2-c2a535d2cca2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local subnet Tensor(\"batch_normalization_45/cond/Merge:0\", shape=(?, 96, 96, 128), dtype=float32)\n",
      "local_out Tensor(\"conv2d_48/Relu:0\", shape=(?, 96, 96, 68), dtype=float32)\n",
      "kernel Tensor(\"lambda_3/Const:0\", shape=(45, 45, 68, 1), dtype=float32)\n",
      "Main 1x1 Tensor(\"lambda_3/Conv2D:0\", shape=(?, 96, 96, 1), dtype=float32)\n",
      "local_out Tensor(\"conv2d_49/BiasAdd:0\", shape=(?, 96, 96, 68), dtype=float32)\n",
      "kernel Tensor(\"lambda_4/Const:0\", shape=(45, 45, 68, 1), dtype=float32)\n",
      "Local output Tensor(\"lambda_4/Conv2D:0\", shape=(?, 96, 96, 1), dtype=float32)\n",
      "Concatenate Tensor(\"concatenate_1/concat:0\", shape=(?, 96, 96, 2), dtype=float32)\n",
      "Reshape Tensor(\"reshape_1/Reshape:0\", shape=(?, 96, 96, 136), dtype=float32)\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_3 (InputLayer)             (None, 96, 96, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)               (None, 96, 96, 128)   3328        input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNor (None, 96, 96, 128)   512         conv2d_33[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)               (None, 96, 96, 128)   409728      batch_normalization_31[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNor (None, 96, 96, 128)   512         conv2d_34[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)               (None, 96, 96, 128)   409728      batch_normalization_32[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNor (None, 96, 96, 128)   512         conv2d_35[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)               (None, 96, 96, 128)   409728      batch_normalization_33[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNor (None, 96, 96, 128)   512         conv2d_36[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)               (None, 96, 96, 128)   409728      batch_normalization_34[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNor (None, 96, 96, 128)   512         conv2d_37[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)               (None, 96, 96, 128)   147584      batch_normalization_35[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNor (None, 96, 96, 128)   512         conv2d_38[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)               (None, 96, 96, 128)   147584      batch_normalization_36[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNor (None, 96, 96, 128)   512         conv2d_39[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)               (None, 96, 96, 128)   147584      batch_normalization_37[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNor (None, 96, 96, 128)   512         conv2d_40[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)               (None, 96, 96, 128)   147584      batch_normalization_38[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNor (None, 96, 96, 128)   512         conv2d_41[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)               (None, 96, 96, 128)   147584      batch_normalization_39[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNor (None, 96, 96, 128)   512         conv2d_42[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)               (None, 96, 96, 128)   147584      batch_normalization_40[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNor (None, 96, 96, 128)   512         conv2d_43[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)               (None, 96, 96, 128)   147584      batch_normalization_41[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNor (None, 96, 96, 128)   512         conv2d_44[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)               (None, 96, 96, 128)   147584      batch_normalization_42[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNor (None, 96, 96, 128)   512         conv2d_45[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)               (None, 96, 96, 128)   147584      batch_normalization_43[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNor (None, 96, 96, 128)   512         conv2d_46[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)               (None, 96, 96, 128)   147584      batch_normalization_44[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNor (None, 96, 96, 128)   512         conv2d_47[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)               (None, 96, 96, 68)    8772        batch_normalization_45[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)               (None, 96, 96, 68)    8772        batch_normalization_45[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)                (None, 68, 96, 96)    0           conv2d_48[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)                (None, 68, 96, 96)    0           conv2d_49[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 68, 96, 192)   0           lambda_3[0][0]                   \n",
      "                                                                   lambda_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)              (None, 96, 96, 136)   0           concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)               (None, 96, 96, 128)   156800      reshape_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNor (None, 96, 96, 128)   512         conv2d_50[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)               (None, 96, 96, 128)   147584      batch_normalization_46[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNor (None, 96, 96, 128)   512         conv2d_51[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)               (None, 96, 96, 128)   147584      batch_normalization_47[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNor (None, 96, 96, 128)   512         conv2d_52[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)               (None, 96, 96, 128)   147584      batch_normalization_48[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNor (None, 96, 96, 128)   512         conv2d_53[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)               (None, 96, 96, 128)   147584      batch_normalization_49[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNor (None, 96, 96, 128)   512         conv2d_54[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)               (None, 96, 96, 128)   147584      batch_normalization_50[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNor (None, 96, 96, 128)   512         conv2d_55[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)               (None, 96, 96, 128)   147584      batch_normalization_51[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNor (None, 96, 96, 128)   512         conv2d_56[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)               (None, 96, 96, 68)    8772        batch_normalization_52[0][0]     \n",
      "====================================================================================================\n",
      "Total params: 4,197,964\n",
      "Trainable params: 4,192,332\n",
      "Non-trainable params: 5,632\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Dropout, Activation, Add\n",
    "from keras.layers import Convolution2D, Lambda, Input, Reshape\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "\n",
    "def apply_kernel(local_out):\n",
    "    '''\n",
    "     get kernel from text file\n",
    "     tile it to 1x1x45x45\n",
    "     convolve with local out\n",
    "    '''\n",
    "    f = open(r'C:\\Users\\Meers\\Documents\\Techie\\InkersIntern\\Phase2\\Merget\\Merget\\network\\config\\kernel45.txt')\n",
    "    kernel45 = np.fromfile(f, dtype = np.float32, count = -1, sep = \" \")\n",
    "    \n",
    "    # [1 x 1 x 45 x 45]\n",
    "    kernel45 = np.reshape(kernel45, (45, 45, 1, 1))\n",
    "    # [numLabels x 1 x 45 x 45] if tensor convolution is used\n",
    "    kernel_stacked \t= np.tile(kernel45, (1, 1, nLabels,1))\n",
    "    #heatmaps = Convolution2D(local_out, kernel_stacked)\n",
    "    kernel_tensor = tf.convert_to_tensor(kernel_stacked, dtype=tf.float32)\n",
    "    print(\"local_out\", local_out)\n",
    "    print(\"kernel\", kernel_tensor)\n",
    "    return tf.nn.conv2d(local_out, kernel_tensor, strides=[1,1,1,1], padding=\"SAME\")\n",
    "    #return heatmaps\n",
    "\n",
    "    '''\n",
    "    local_subnet_np = local_out.eval \n",
    "    heatmaps = []\n",
    "    for landmark in local_subnet_np:\n",
    "        heatmaps.append(cv2.filter2D(landmark,-1,kernel45))\n",
    "    return tf.convert_to_tensor(heatmaps, dtype=tf.float32)\n",
    "    '''\n",
    "\n",
    "'''\n",
    "LOCAL SUBNET\n",
    "'''\n",
    "\n",
    "# [ImageC x ImageH x ImageW]\n",
    "\n",
    "input_img = Input(( image_H, image_W, img_channels))\n",
    "model = Convolution2D(filters=nFilters, kernel_size=(5, 5), padding='same', activation='relu')(input_img)\n",
    "model = BatchNormalization()(model)\n",
    "model = Convolution2D(filters=nFilters, kernel_size=(5, 5), padding='same', activation='relu')(model)\n",
    "model = BatchNormalization()(model)\n",
    "model = Convolution2D(filters=nFilters, kernel_size=(5, 5), padding='same', activation='relu')(model)\n",
    "model = BatchNormalization()(model)\n",
    "model = Convolution2D(filters=nFilters, kernel_size=(5, 5), padding='same', activation='relu')(model)\n",
    "model = BatchNormalization()(model)\n",
    "model = Convolution2D(filters=nFilters, kernel_size=(5, 5), padding='same', activation='relu')(model)\n",
    "model = BatchNormalization()(model)\n",
    "\n",
    "model = Convolution2D(filters=nFilters, kernel_size=(3, 3), padding='same', activation='relu')(model)\n",
    "model = BatchNormalization()(model)\n",
    "model = Convolution2D(filters=nFilters, kernel_size=(3, 3), padding='same', activation='relu')(model)\n",
    "model = BatchNormalization()(model)\n",
    "model = Convolution2D(filters=nFilters, kernel_size=(3, 3), padding='same', activation='relu')(model)\n",
    "model = BatchNormalization()(model)\n",
    "model = Convolution2D(filters=nFilters, kernel_size=(3, 3), padding='same', activation='relu')(model)\n",
    "model = BatchNormalization()(model)\n",
    "model = Convolution2D(filters=nFilters, kernel_size=(3, 3), padding='same', activation='relu')(model)\n",
    "model = BatchNormalization()(model)\n",
    "model = Convolution2D(filters=nFilters, kernel_size=(3, 3), padding='same', activation='relu')(model)\n",
    "model = BatchNormalization()(model)\n",
    "model = Convolution2D(filters=nFilters, kernel_size=(3, 3), padding='same', activation='relu')(model)\n",
    "model = BatchNormalization()(model)\n",
    "model = Convolution2D(filters=nFilters, kernel_size=(3, 3), padding='same', activation='relu')(model)\n",
    "model = BatchNormalization()(model)\n",
    "model = Convolution2D(filters=nFilters, kernel_size=(3, 3), padding='same', activation='relu')(model)\n",
    "model = BatchNormalization()(model)\n",
    "model = Convolution2D(filters=nFilters, kernel_size=(3, 3), padding='same', activation='relu')(model)\n",
    "model = BatchNormalization()(model)\n",
    "print(\"Local subnet\", model)\n",
    "'''\n",
    "1x1 Convolution with activation\n",
    "'''\n",
    "model_Conv = Convolution2D(filters=nLabels, kernel_size=(1, 1),activation='relu')(model)\n",
    "model_Conv = Lambda(apply_kernel, output_shape=(nLabels, img_cols, img_rows))(model_Conv)\n",
    "print(\"Main 1x1\", model_Conv)\n",
    "'''\n",
    "Ol 1x1 Linear convolution\n",
    "Apply Gaussian Kernel filter\n",
    "'''\n",
    "model_Ol = Convolution2D(filters=nLabels, kernel_size=(1, 1),activation=None)(model)\n",
    "# What about tiling the kernels????\n",
    "model_Ol = Lambda(apply_kernel, output_shape=(nLabels, img_cols, img_rows))(model_Ol)\n",
    "print(\"Local output\", model_Ol)\n",
    "\n",
    "output_Ol = keras.layers.concatenate([model_Conv, model_Ol])\n",
    "print(\"Concatenate\", output_Ol)\n",
    "output_Ol = Reshape((96, 96,-1))(output_Ol)\n",
    "print(\"Reshape\", output_Ol)\n",
    "\n",
    "'''\n",
    "GLOBAL SUBNET\n",
    "'''\n",
    "model = Convolution2D(filters=nFilters, kernel_size=(3, 3), padding='same', dilation_rate = 4, activation='relu')(output_Ol)\n",
    "model = BatchNormalization()(model)\n",
    "model = Convolution2D(filters=nFilters, kernel_size=(3, 3), padding='same', dilation_rate = 4, activation='relu')(model)\n",
    "model = BatchNormalization()(model)\n",
    "model = Convolution2D(filters=nFilters, kernel_size=(3, 3), padding='same', dilation_rate = 4, activation='relu')(model)\n",
    "model = BatchNormalization()(model)\n",
    "model = Convolution2D(filters=nFilters, kernel_size=(3, 3), padding='same', dilation_rate = 4, activation='relu')(model)\n",
    "model = BatchNormalization()(model)\n",
    "model = Convolution2D(filters=nFilters, kernel_size=(3, 3), padding='same', dilation_rate = 4, activation='relu')(model)\n",
    "model = BatchNormalization()(model)\n",
    "model = Convolution2D(filters=nFilters, kernel_size=(3, 3), padding='same', dilation_rate = 4, activation='relu')(model)\n",
    "model = BatchNormalization()(model)\n",
    "model = Convolution2D(filters=nFilters, kernel_size=(3, 3), padding='same', dilation_rate = 4, activation='relu')(model)\n",
    "model = BatchNormalization()(model)\n",
    "model = Convolution2D(filters=nLabels, kernel_size=(1, 1), activation=None)(model)\n",
    "FLD_model = Model(inputs = input_img, outputs=model)\n",
    "FLD_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* Loss Function: Weighted Square Error\n",
    "* Exclude non-labeled landmarks from the loss\n",
    "* Weight each of N landmarks depending on whether they lie within the image boundary:\n",
    "\\begin{equation*}\n",
    "wij = V (i,j) + \\frac{L(i,j)}{10} + \\frac{L(i,j)}{2N}\\sum_{k=1}^N V (i,k),       \\\\[1pt]\n",
    "\\text{    where V (i; j) and L(i; j) are indicator functions with L(i; j) = 1 iff landmark j in face i is labeled}    \\\\[1pt]\n",
    "\\text {V (i; j) = 1 iff landmark j in face i is within the image boundary, zero otherwise.    }\\\\[1pt]\n",
    "\\text{Note that L(i; j) = 0 implies V (i; j) = 0.}\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "e_i = \\sum_{n=1}^N w_{in}(((O^l_n - G_n) * K)^2 + (O^g_n - G_n * K)^2), \\\\[2pt]\n",
    "\\text{    where    } \\\\[2pt]\n",
    "O^l_n    and    O^g_n = \\text{nth channels of the local- and global context subnet outputs, respectively.} \\\\[1pt]\n",
    "\\text{K = kernel }   \\\\[1pt]\n",
    "\\text{Gn = ground truth heatmap for landmark n }   \\\\[1pt]\n",
    "\\text{For efficiency, the kernel convolution after stacking is reused for the loss}\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "def landmark_weight(labels):\n",
    "    #[numLabels x 1 x 1]\n",
    "    Win = tf.reduce_mean(labels)\n",
    "    Win = tf.multiply(Win, 0.5)\n",
    "    return Win\n",
    "\n",
    "'''\n",
    "Ol - [numLabels x ImageH x ImageW] Kernel conv already applied in Network\n",
    "Og - [numLabels x ImageH x ImageW]\n",
    "labels - Landmark coordinates [numLabels x ImageH x ImageW] without heatmaps\n",
    "'''\n",
    "def loss_function(Og, labels):#Ol, Og,labels):\n",
    "    \n",
    "    # Gn = labels x K\n",
    "    Gn = apply_kernel(labels)\n",
    "\n",
    "    Win = landmark_weight(labels)\n",
    "    \n",
    "    # Og - Gn\n",
    "    global_diff = tf.subtract(Og, Gn)\n",
    "    global_err = tf.square(global_diff)\n",
    "    \n",
    "    # Ol - Gn\n",
    "    local_diff = tf.subtract(model_Ol, Gn)\n",
    "    local_err = tf.square(local_diff)\n",
    "    \n",
    "    comb_err = tf.add(local_err, global_err)\n",
    "    \n",
    "    wt_square_err = tf.reduce_sum(Win * comb_err)\n",
    "    return wt_square_err    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_out Tensor(\"conv2d_57/BiasAdd:0\", shape=(?, 96, 96, 68), dtype=float32)\n",
      "kernel Tensor(\"loss_1/conv2d_57_loss/Const:0\", shape=(45, 45, 68, 1), dtype=float32)\n",
      "WARNING:tensorflow:From C:\\Users\\Meers\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1290: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "FLD_model.compile(optimizer='sgd',\n",
    "              loss=loss_function,\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cntk as C\n",
    "\n",
    "cntk_model = C.load_model(r\"C:\\Users\\Meers\\Documents\\Techie\\InkersIntern\\Phase2\\Merget\\Merget\\python\\output\\models\\model.21\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter('W', [], [68 x 128 x 1 x 1]),\n",
       " Parameter('b', [], [68 x 1 x 1]),\n",
       " Parameter('scale', [], [128]),\n",
       " Parameter('bias', [], [128]),\n",
       " Parameter('W', [], [128 x 128 x 3 x 3]),\n",
       " Parameter('b', [], [128 x 1 x 1]),\n",
       " Parameter('scale', [], [128]),\n",
       " Parameter('bias', [], [128]),\n",
       " Parameter('W', [], [128 x 128 x 3 x 3]),\n",
       " Parameter('b', [], [128 x 1 x 1]),\n",
       " Parameter('scale', [], [128]),\n",
       " Parameter('bias', [], [128]),\n",
       " Parameter('W', [], [128 x 128 x 3 x 3]),\n",
       " Parameter('b', [], [128 x 1 x 1]),\n",
       " Parameter('scale', [], [128]),\n",
       " Parameter('bias', [], [128]),\n",
       " Parameter('W', [], [128 x 128 x 3 x 3]),\n",
       " Parameter('b', [], [128 x 1 x 1]),\n",
       " Parameter('scale', [], [128]),\n",
       " Parameter('bias', [], [128]),\n",
       " Parameter('W', [], [128 x 128 x 3 x 3]),\n",
       " Parameter('b', [], [128 x 1 x 1]),\n",
       " Parameter('scale', [], [128]),\n",
       " Parameter('bias', [], [128]),\n",
       " Parameter('W', [], [128 x 128 x 3 x 3]),\n",
       " Parameter('b', [], [128 x 1 x 1]),\n",
       " Parameter('scale', [], [128]),\n",
       " Parameter('bias', [], [128]),\n",
       " Parameter('W', [], [128 x 136 x 3 x 3]),\n",
       " Parameter('b', [], [128 x 1 x 1]),\n",
       " Parameter('W', [], [68 x 128 x 1 x 1]),\n",
       " Parameter('b', [], [68 x 1 x 1]),\n",
       " Parameter('scale', [], [128]),\n",
       " Parameter('bias', [], [128]),\n",
       " Parameter('W', [], [128 x 128 x 3 x 3]),\n",
       " Parameter('b', [], [128 x 1 x 1]),\n",
       " Parameter('scale', [], [128]),\n",
       " Parameter('bias', [], [128]),\n",
       " Parameter('W', [], [128 x 128 x 3 x 3]),\n",
       " Parameter('b', [], [128 x 1 x 1]),\n",
       " Parameter('scale', [], [128]),\n",
       " Parameter('bias', [], [128]),\n",
       " Parameter('W', [], [128 x 128 x 3 x 3]),\n",
       " Parameter('b', [], [128 x 1 x 1]),\n",
       " Parameter('scale', [], [128]),\n",
       " Parameter('bias', [], [128]),\n",
       " Parameter('W', [], [128 x 128 x 3 x 3]),\n",
       " Parameter('b', [], [128 x 1 x 1]),\n",
       " Parameter('scale', [], [128]),\n",
       " Parameter('bias', [], [128]),\n",
       " Parameter('W', [], [128 x 128 x 3 x 3]),\n",
       " Parameter('b', [], [128 x 1 x 1]),\n",
       " Parameter('scale', [], [128]),\n",
       " Parameter('bias', [], [128]),\n",
       " Parameter('W', [], [128 x 128 x 3 x 3]),\n",
       " Parameter('b', [], [128 x 1 x 1]),\n",
       " Parameter('scale', [], [128]),\n",
       " Parameter('bias', [], [128]),\n",
       " Parameter('W', [], [128 x 128 x 3 x 3]),\n",
       " Parameter('b', [], [128 x 1 x 1]),\n",
       " Parameter('scale', [], [128]),\n",
       " Parameter('bias', [], [128]),\n",
       " Parameter('W', [], [128 x 128 x 3 x 3]),\n",
       " Parameter('b', [], [128 x 1 x 1]),\n",
       " Parameter('scale', [], [128]),\n",
       " Parameter('bias', [], [128]),\n",
       " Parameter('W', [], [128 x 128 x 3 x 3]),\n",
       " Parameter('b', [], [128 x 1 x 1]),\n",
       " Parameter('scale', [], [128]),\n",
       " Parameter('bias', [], [128]),\n",
       " Parameter('W', [], [128 x 128 x 3 x 3]),\n",
       " Parameter('b', [], [128 x 1 x 1]),\n",
       " Parameter('scale', [], [128]),\n",
       " Parameter('bias', [], [128]),\n",
       " Parameter('W', [], [128 x 128 x 5 x 5]),\n",
       " Parameter('b', [], [128 x 1 x 1]),\n",
       " Parameter('scale', [], [128]),\n",
       " Parameter('bias', [], [128]),\n",
       " Parameter('W', [], [128 x 128 x 5 x 5]),\n",
       " Parameter('b', [], [128 x 1 x 1]),\n",
       " Parameter('scale', [], [128]),\n",
       " Parameter('bias', [], [128]),\n",
       " Parameter('W', [], [128 x 128 x 5 x 5]),\n",
       " Parameter('b', [], [128 x 1 x 1]),\n",
       " Parameter('scale', [], [128]),\n",
       " Parameter('bias', [], [128]),\n",
       " Parameter('W', [], [128 x 128 x 5 x 5]),\n",
       " Parameter('b', [], [128 x 1 x 1]),\n",
       " Parameter('scale', [], [128]),\n",
       " Parameter('bias', [], [128]),\n",
       " Parameter('W', [], [128 x 1 x 5 x 5]),\n",
       " Parameter('b', [], [128 x 1 x 1]),\n",
       " Parameter('scale', [], [68]),\n",
       " Parameter('bias', [], [68]),\n",
       " Parameter('W', [], [68 x 128 x 1 x 1]),\n",
       " Parameter('b', [], [68 x 1 x 1]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cntk_model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cntk_model.save(\"cntk_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (File signature not found)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-c578da124c73>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mFLD\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"C:\\Users\\Meers\\Documents\\Techie\\InkersIntern\\Phase2\\FLDCode\\cntk_model.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m         \u001b[1;31m# instantiate model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m         \u001b[0mmodel_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model_config'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m                 \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to open file (File signature not found)"
     ]
    }
   ],
   "source": [
    "FLD = keras.models.load_model(r\"C:\\Users\\Meers\\Documents\\Techie\\InkersIntern\\Phase2\\FLDCode\\cntk_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.backend' has no attribute 'load_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-0eaf48e6b126>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#save_model_hdf5(cntk_model, 'my_model.h5')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mkerasmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcntk_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras.backend' has no attribute 'load_model'"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "#save_model_hdf5(cntk_model, 'my_model.h5')\n",
    "kerasmodel = K.functional_ops. load_model(cntk_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#func = cntk_model.outputs[0]\n",
    "cntk_model.save('cntk_model.onnx', format=C.ModelFormat.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "onnx_model = onnx.load('cntk_model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "Required attribute 'consumed_inputs' is missing.\n\n==> Context: Bad node spec: input: \"Plus5153_Output_0\" input: \"Parameter106\" input: \"Parameter107\" input: \"Constant108\" input: \"Constant109\" output: \"BatchNormalization5165_Output_0\" name: \"BatchNormalization5165\" op_type: \"BatchNormalization\" attribute { name: \"spatial\" i: 1 type: INT } attribute { name: \"is_test\" i: 1 type: INT } attribute { name: \"epsilon\" f: 1e-05 type: FLOAT } attribute { name: \"momentum\" f: 0 type: FLOAT } doc_string: \"\" domain: \"\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-98295415440b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0monnx_tf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprepare\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtf_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0monnx_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\onnx_tf\\backend.py\u001b[0m in \u001b[0;36mprepare\u001b[1;34m(cls, model, device, **kwargs)\u001b[0m\n\u001b[0;32m    343\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mreturns\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mTensorflowRep\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mrepresenting\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mONNX\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \"\"\"\n\u001b[1;32m--> 345\u001b[1;33m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensorflowBackendBase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m     predict_net = (cls.onnx_graph_to_tensorflow_net(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\onnx\\backend\\base.py\u001b[0m in \u001b[0;36mprepare\u001b[1;34m(cls, model, device, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m                 ):  # type: (...) -> Optional[BackendRep]\n\u001b[0;32m     64\u001b[0m         \u001b[1;31m# TODO Remove Optional from return type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[0monnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchecker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\onnx\\checker.py\u001b[0m in \u001b[0;36mcheck_model\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcheck_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# type: (ModelProto) -> None\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m     \u001b[0mC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValidationError\u001b[0m: Required attribute 'consumed_inputs' is missing.\n\n==> Context: Bad node spec: input: \"Plus5153_Output_0\" input: \"Parameter106\" input: \"Parameter107\" input: \"Constant108\" input: \"Constant109\" output: \"BatchNormalization5165_Output_0\" name: \"BatchNormalization5165\" op_type: \"BatchNormalization\" attribute { name: \"spatial\" i: 1 type: INT } attribute { name: \"is_test\" i: 1 type: INT } attribute { name: \"epsilon\" f: 1e-05 type: FLOAT } attribute { name: \"momentum\" f: 0 type: FLOAT } doc_string: \"\" domain: \"\""
     ]
    }
   ],
   "source": [
    "from onnx_tf.backend import prepare\n",
    "tf_model = prepare(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LandMarkExecution.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
